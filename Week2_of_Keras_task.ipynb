{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week2_of Keras-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redsun1988/Introduction-to-neural-networks/blob/master/Week2_of_Keras_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQt8M_1SOJlt",
        "colab_type": "text"
      },
      "source": [
        "# Getting deeper with Keras\n",
        "* Tensorflow is a powerful and flexible tool, but coding large neural architectures with it is tedious.\n",
        "* There are plenty of deep learning toolkits that work on top of it like Slim, TFLearn, Sonnet, Keras.\n",
        "* Choice is matter of taste and particular task\n",
        "* We'll be using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGd-fRYOwl5",
        "colab_type": "code",
        "outputId": "a0b1f8d6-5850-4d3d-c25e-6088644db2b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "\n",
        "setup_google_colab.setup_week2()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-07-02 19:55:27--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-02 19:55:28 (88.7 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n",
            "**************************************************\n",
            "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "****************************\n",
            "cifar-10-batches-py.tar.gz\n",
            "**************************************************\n",
            "mnist.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km1_K27mOJlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import grading"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffclgdqnOJl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use preloaded keras datasets and models\n",
        "! mkdir -p ~/.keras/datasets\n",
        "! mkdir -p ~/.keras/models\n",
        "! ln -s $(realpath ../readonly/keras/datasets/*) ~/.keras/datasets/\n",
        "! ln -s $(realpath ../readonly/keras/models/*) ~/.keras/models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTm5BWqhOJl3",
        "colab_type": "code",
        "outputId": "48ce352e-525e-4f88-a3ba-a1a6b4bda62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from preprocessed_mnist import load_dataset\n",
        "import keras\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
        "y_train,y_val,y_test = map(keras.utils.np_utils.to_categorical,[y_train,y_val,y_test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "svuBHezWOJl9",
        "colab_type": "code",
        "outputId": "7e8fc629-bf40-48e5-b485-a87c66386ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8fAqwrEOJmC",
        "colab_type": "text"
      },
      "source": [
        "## The pretty keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7yP4CPoOJmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras_utils import reset_tf_session\n",
        "s = reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HV_ssrLOJmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "import keras.layers as ll\n",
        "\n",
        "model = Sequential(name=\"mlp\")\n",
        "\n",
        "model.add(ll.InputLayer([28, 28]))\n",
        "\n",
        "model.add(ll.Flatten())\n",
        "\n",
        "# network body\n",
        "model.add(ll.Dense(120))\n",
        "model.add(ll.Activation('sigmoid'))\n",
        "\n",
        "model.add(ll.Dense(25))\n",
        "model.add(ll.Activation('sigmoid'))\n",
        "\n",
        "# output layer: 10 neurons for each class with softmax\n",
        "model.add(ll.Dense(10, activation='softmax'))\n",
        "\n",
        "# categorical_crossentropy is your good old crossentropy\n",
        "# but applied for one-hot-encoded vectors\n",
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt0tiKbCOJmJ",
        "colab_type": "code",
        "outputId": "255082ef-981c-4c89-b513-417c9cb82b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               94200     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                3025      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 97,485\n",
            "Trainable params: 97,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm6-N-NaOJmN",
        "colab_type": "text"
      },
      "source": [
        "### Model interface\n",
        "\n",
        "Keras models follow __Scikit-learn__'s interface of fit/predict with some notable extensions. Let's take a tour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "609jkvtiOJmO",
        "colab_type": "code",
        "outputId": "1a1b9046-11f8-4575-cf67-c36cf5d54d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# fit(X,y) ships with a neat automatic logging.\n",
        "#          Highly customizable under the hood.\n",
        "model.fit(X_train, y_train,\n",
        "          validation_data=(X_val, y_val), epochs=15);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0729 - acc: 0.9795 - val_loss: 0.0895 - val_acc: 0.9737\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0598 - acc: 0.9831 - val_loss: 0.0899 - val_acc: 0.9732\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0490 - acc: 0.9867 - val_loss: 0.0799 - val_acc: 0.9768\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0406 - acc: 0.9891 - val_loss: 0.0807 - val_acc: 0.9759\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0834 - val_acc: 0.9762\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0269 - acc: 0.9934 - val_loss: 0.0801 - val_acc: 0.9765\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0221 - acc: 0.9950 - val_loss: 0.0811 - val_acc: 0.9761\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0179 - acc: 0.9960 - val_loss: 0.0792 - val_acc: 0.9774\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0854 - val_acc: 0.9767\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0121 - acc: 0.9974 - val_loss: 0.0842 - val_acc: 0.9760\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0841 - val_acc: 0.9767\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0853 - val_acc: 0.9772\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0873 - val_acc: 0.9784\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0053 - acc: 0.9990 - val_loss: 0.0879 - val_acc: 0.9775\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 6s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0880 - val_acc: 0.9788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXrXIXr0OJmR",
        "colab_type": "code",
        "outputId": "29c7195f-9006-4efe-936d-27014226030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# estimate probabilities P(y|x)\n",
        "model.predict_proba(X_val[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r2/2 [==============================] - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.8316288e-10, 1.3421995e-07, 5.3452152e-07, 9.9999595e-01,\n",
              "        1.4349193e-11, 1.4071168e-06, 4.1545348e-10, 1.0613577e-08,\n",
              "        1.4596675e-06, 5.4320731e-07],\n",
              "       [1.7915908e-09, 1.2223562e-08, 3.1934755e-07, 1.3002623e-06,\n",
              "        1.9571020e-07, 1.0692682e-07, 4.1946127e-08, 1.3782478e-09,\n",
              "        9.9999774e-01, 2.6328979e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bZzTY3jOJmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save trained weights\n",
        "model.save(\"weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR2UZQQSOJmY",
        "colab_type": "code",
        "outputId": "60c2b07b-0233-487d-bd0d-6f64fae5d8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"\\nLoss, Accuracy = \", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 9984/10000 [============================>.] - ETA: 0s\n",
            "Loss, Accuracy =  [0.08629054103391827, 0.9773]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKWHy0K8OJmc",
        "colab_type": "text"
      },
      "source": [
        "### Whoops!\n",
        "So far, our model is staggeringly inefficient. There is something wrong with it. Guess, what?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcov1y22OJmd",
        "colab_type": "code",
        "outputId": "d3e62245-9b9d-48b6-d6bf-12f5488573ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Test score...\n",
        "test_predictions = model.predict_proba(X_test).argmax(axis=-1)\n",
        "test_answers = y_test.argmax(axis=-1)\n",
        "\n",
        "test_accuracy = np.mean(test_predictions==test_answers)\n",
        "\n",
        "print(\"\\nTest accuracy: {} %\".format(test_accuracy*100))\n",
        "\n",
        "assert test_accuracy>=0.92,\"Logistic regression can do better!\"\n",
        "assert test_accuracy>=0.975,\"Your network can do better!\"\n",
        "print(\"Great job!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 9248/10000 [==========================>...] - ETA: 0s\n",
            "Test accuracy: 97.72999999999999 %\n",
            "Great job!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOL-4iukOJmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_submitter = grading.Grader(\"0ybD9ZxxEeea8A6GzH-6CA\")\n",
        "answer_submitter.set_answer(\"N56DR\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-clxOiOJmq",
        "colab_type": "code",
        "outputId": "aeb7b64a-ba1c-400e-d3c0-d049d00f535c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answer_submitter.submit(\"redsun1988@rambler.ru\", \"Ypr1kAQ4mQXzlsEa\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You used a token for \"MNIST digits classification with TF\" in \"Introduction to Deep Learning\". Please use a token for the assignment you are submitting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB8hX2J0OJmt",
        "colab_type": "text"
      },
      "source": [
        "## Keras + tensorboard\n",
        "\n",
        "Remember the interactive graphs from Tensorboard one notebook ago? \n",
        "\n",
        "Thing is, Keras can use tensorboard to show you a lot of useful information about the learning progress. Just take a look!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sny4Mv0ZOJmu",
        "colab_type": "code",
        "outputId": "74049c83-28b8-417c-bf2a-a8219a3c8ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! rm -r /tmp/tboard/**"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/tmp/tboard/**': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyuXNuWSOJm5",
        "colab_type": "code",
        "outputId": "d57c76a4-15b9-4907-e099-e5c232d09af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
        "          epochs=10,\n",
        "          callbacks=[TensorBoard(\"/tmp/tboard\")])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 20:18:37.185787 139989977253760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:699: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0702 20:18:37.188994 139989977253760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:702: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0894 - val_acc: 0.9795\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0964 - val_acc: 0.9782\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0894 - val_acc: 0.9801\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0034 - acc: 0.9990 - val_loss: 0.1037 - val_acc: 0.9768\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0953 - val_acc: 0.9779\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 6s - loss: 6.1752e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9787\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1022 - val_acc: 0.9767\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 6s - loss: 8.3124e-04 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9796\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 6s - loss: 4.2769e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9800\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 6s - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0994 - val_acc: 0.9808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f518a533e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypve0R-9OJm9",
        "colab_type": "text"
      },
      "source": [
        "# Tips & tricks\n",
        "\n",
        "Here are some tips on what you could do. Don't worry, to reach the passing threshold you don't need to try all the ideas listed here, feel free to stop once you reach the 0.975 accuracy mark.\n",
        "\n",
        " * __Network size__\n",
        "   * More neurons, \n",
        "   * More layers, ([docs](https://keras.io/))\n",
        "\n",
        "   * Nonlinearities in the hidden layers\n",
        "     * tanh, relu, leaky relu, etc\n",
        "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
        "\n",
        "\n",
        " * __Early Stopping__\n",
        "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
        "   * Some networks converge over 5 epochs, others - over 500.\n",
        "   * Way to go: stop when validation score is 10 iterations past maximum\n",
        "     \n",
        "\n",
        " * __Faster optimization__\n",
        "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
        "     * Converge faster and sometimes reach better optima\n",
        "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
        "\n",
        "\n",
        " * __Regularize__ to prevent overfitting\n",
        "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
        "     * Can be done manually or via - https://keras.io/regularizers/\n",
        "   \n",
        "   \n",
        " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
        "   * https://keras.io/preprocessing/image/\n",
        "   * Zoom-in+slice = move\n",
        "   * Rotate+zoom(to remove black stripes)\n",
        "   * any other perturbations\n",
        "   * Simple way to do that (if you have PIL/Image): \n",
        "     * ```from scipy.misc import imrotate,imresize```\n",
        "     * and a few slicing\n",
        "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
      ]
    }
  ]
}