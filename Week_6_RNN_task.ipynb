{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Week 6 RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redsun1988/Introduction-to-neural-networks/blob/master/Week_6_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C8JCIHMcJmK",
        "colab_type": "code",
        "outputId": "392c86d2-9e4e-4081-c405-f175138c840c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-08-05 19:45:33--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-05 19:45:33 (65.0 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIguxxA7b69R",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "ZQd2Icjxb69U",
        "colab_type": "code",
        "outputId": "15ea6bbb-668e-471c-f2bc-786a4c69f0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj7mV7bdb69x",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "scH4J2IIb69y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "3g-iV_kib691",
        "colab_type": "code",
        "outputId": "9996ee4d-673e-43c9-fdb9-2ff635f573f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "P8anH0lnb693",
        "colab_type": "code",
        "outputId": "6f7ca3a7-1332-4210-f2f9-f43f3b8ca6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGntJREFUeJzt3X+UXWV97/H3h/CjgPwIZgyQBCZi\nQIGlAaeAVRAvBcKPS9B7i6FeCIoGWrB6ZV0v0NtCRbpSK6WyxNAAaaBCMOVHSQWESFVKa5AJxpBA\nkAECmTBJBsMPC65o4Hv/2M/oZjhn5vyaOQnP57XWWbPP93n2s7/7THK+Zz97n9mKCMzMLE/btDsB\nMzNrHxcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAva1JCknvacN2j5bU28T6l0r6dlreR9J/\nSRrTotyukfQXrcizwthHSnqiVePZyHMRyICkj0j6T0kvS9oo6T8k/X6783o7GcliExHPRcQ7IuL1\nYXI4S9KDNYx3bkRc1orcBu93RPx7RBzQirFtdGzb7gRsZEnaFfgu8CfAQmB74EhgUzvzsvaQNGa4\nYmJ58ZHA29/+ABGxICJej4hfRcR9EbF8oIOkz0h6XNKLku6VtG+p7VhJq9JRxDcl/UjSZ1Pbb6cs\n0vPO9Mlw2/R8N0nXS+qTtFbSVwemNAY+tUr6etruM5JOKI21h6R/lPR8av+XUtvJkpZJeikd4by/\nlhdC0g5pe89JWp+mRXZMbUdL6pV0gaQNKedPl9Z9p6R/lfSKpIfTvjyY2h5I3X6Wpm0+WVqv4ngV\ncpucXttfSloMjBvidT1L0tOp7zOSPiXpfcA1wIdSDi+lvvMlzZF0t6RXgY+l2FcHbf9iSS9IWi3p\nU6X4Dwd+3+XfW7X9Hjy9JOl9aYyXJK2UdEqpbb6kqyXdlfblIUn7Dfd7tNZyEXj7+znwuqQbJJ0g\naWy5UdJ04GLgE0AH8O/AgtQ2Drgd+H8Ub0pPAR+uY9vzgc3Ae4BDgOOAz5baDweeSGN/DbheklLb\nPwE7AQcB7wKuTDkdAswDzgHeCfwDsEjSDjXkM5uiKE5NOU0A/rLUviewW4qfDVxder2uBl5NfWam\nBwARcVRa/ECatvlODeMNdjOwNL0Wl5XHL5O0M3AVcEJE7AL8AbAsIh4HzgV+nHLYvbTaHwOXA7sA\nlaaL9kzbnZC2O1fSsFM6Q+z3QK7bAf8K3EfxO/w8cNOgsWcAfwWMBXpSnjaaIsKPt/kDeB/FG3Iv\nxZvyImB8arsHOLvUdxvgNWBf4ExgSalNaYzPpueXAt8utXcCQTHNOJ5iymnHUvvpwA/S8llAT6lt\np7TunsBewBvA2Ar7Mge4bFDsCeCjVfY9KN7wRfEmvl+p7UPAM2n5aOBXwLal9g3AEcAY4DfAAaW2\nrwIPDt5O6XnV8SrkuE/6vexcit088NoOel13Bl4C/kf5tS29pg8Ois0HbqwQ+2opz8HbXgj8RVr+\n4cDvu9I2qux3b1o+ElgHbFNqXwBcWsrjulLbicCqdv9/ye3hI4EMRMTjEXFWREwEDgb2Bv4+Ne8L\nfCMdrr8EbKR4w5yQ+q0pjRPl58PYF9gO6CuN/Q8UnwgHrCuN/VpafAcwCdgYES9WGfeCgTHTuJNS\nrkPpoCg0S0vrfS/FB/wiIjaXnr+W8umgeAMu73str0O18QbbG3gxIl4txZ6tNGDq80mKT/19aSrl\nvcPkMVyulbY93OtZi72BNRHxxqCxJ5SerystV3t9bAS5CGQmIlZRfAI7OIXWAOdExO6lx44R8Z9A\nH8UbLABpqmZSabhXKd5YB+xZWl5DcSQwrjTurhFxUA1prgH2kLR7lbbLB+W7U0QsGGbMFyg+mR9U\nWm+3iKjlTaef4tPyxFJsUpW+jegDxqapngH7VOscEfdGxLEUR0yrgGsHmqqtMsz2K237+bQ81O94\nOM8DkySV32f2AdbWMYaNMBeBtzlJ700nJyem55MopmWWpC7XABdJOii17ybpj1LbXcBBkj6RTkr+\nGW9+E1gGHKXiOvbdgIsGGiKij2Iu+ApJu0raRtJ+kj46XM5p3XuAb0kaK2k7SQPzz9cC50o6XIWd\nJZ0kaZdhxnwjrXulpHelfZ0g6fga8nmd4tzIpZJ2Sp+8zxzUbT3w7uHGqjL+s0A38FeStpf0EeC/\nV+orabyk6elNexPwXxRTZwM5TJS0fQNpDGz7SOBk4J9TfBnwibTf76E4t1E21H4/RPHp/svpd3h0\n2q9bGsjPRoiLwNvfLylOwD6Urg5ZAqwALgCIiDuAvwFukfRKajshtb0A/BHFCdVfAFOA/xgYOCIW\nA98BllOc1PzuoG2fSXFJ6mPAi8CtFJ9ea3EGxTz8Koq59C+mbXYDnwO+mcbsoZinrsX/Tf2XpH39\nPlDrNe3nU5zkXUdx0noBb77M9lLghjTVdFqNY5b9McXvaSNwCXBjlX7bAF+i+JS9EfgoxeW/AP8G\nrATWSXqhjm2vo3gtnwduAs5NR4xQnJD/NcWb/Q2pvexSqux3RPya4k3/BIojsW8BZ5bGti2Aimle\ns9pI+iHFCcvr2p1LO0n6G2DPiKh4FY/Z1sJHAmY1SNNq709TUIdRTIvc0e68zJrlbwyb1WYXiimg\nvSmmRq4A7mxrRmYt4OkgM7OMeTrIzCxjW/x00Lhx46Kzs7PdaZiZbTWWLl36QkR0DN9zKygCnZ2d\ndHd3tzsNM7OthqSK3zivxNNBZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDM\nLGMuAmZmGdvivzFsW5bOC++qq//q2SeNUCZm1go+EjAzy9iwRUDSJEk/kPSYpJWSvpDie0haLOnJ\n9HNsikvSVZJ6JC2XdGhprJmp/5OSfEcmM7M2q+VIYDNwQUQcCBwBnCfpQOBC4P6ImALcn55DcT/R\nKekxC5gDRdGguHfq4cBhwCUDhcPMzNpj2CIQEX0R8Uha/iXwODABmE5x42nSz1PT8nTgxigsAXaX\ntBdwPLA4IjZGxIvAYmBaS/fGzMzqUtc5AUmdwCHAQ8D4iOhLTeuA8Wl5ArCmtFpvilWLV9rOLEnd\nkrr7+/vrSdHMzOpQcxGQ9A7gNuCLEfFKuS2Ke1S27D6VETE3Iroioqujo6b7IpiZWQNqKgKStqMo\nADdFxO0pvD5N85B+bkjxtcCk0uoTU6xa3MzM2qSWq4MEXA88HhF/V2paBAxc4TMTuLMUPzNdJXQE\n8HKaNroXOE7S2HRC+LgUMzOzNqnly2IfBs4AHpW0LMUuBmYDCyWdDTwLnJba7gZOBHqA14BPA0TE\nRkmXAQ+nfl+JiI0t2QszM2vIsEUgIh4EVKX5mAr9AzivyljzgHn1JGhmZiPH3xg2M8uYi4CZWcZc\nBMzMMuYiYGaWMRcBM7OMuQiYmWXMN5V5m/FNX8ysHj4SMDPLmIuAmVnGXATMzDLmImBmljEXATOz\njLkImJllzEXAzCxjLgJmZhlzETAzy1gtt5ecJ2mDpBWl2HckLUuP1QN3HJPUKelXpbZrSut8UNKj\nknokXZVuW2lmZm1Uy5+NmA98E7hxIBARnxxYlnQF8HKp/1MRMbXCOHOAzwEPUdyCchpwT/0pm5lZ\nqwx7JBARDwAV7wWcPs2fBiwYagxJewG7RsSSdPvJG4FT60/XzMxaqdlzAkcC6yPiyVJssqSfSvqR\npCNTbALQW+rTm2IVSZolqVtSd39/f5MpmplZNc0WgdN581FAH7BPRBwCfAm4WdKu9Q4aEXMjoisi\nujo6OppM0czMqmn4T0lL2hb4BPDBgVhEbAI2peWlkp4C9gfWAhNLq09MMTMza6NmjgT+EFgVEb+d\n5pHUIWlMWn43MAV4OiL6gFckHZHOI5wJ3NnEts3MrAVquUR0AfBj4ABJvZLOTk0zeOsJ4aOA5emS\n0VuBcyNi4KTynwLXAT3AU/jKIDOztht2OigiTq8SP6tC7Dbgtir9u4GD68zPzMxGkL8xbGaWMRcB\nM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxj\nLgJmZhlzETAzy5iLgJlZxlwEzMwyVsudxeZJ2iBpRSl2qaS1kpalx4mltosk9Uh6QtLxpfi0FOuR\ndGHrd8XMzOpVy5HAfGBahfiVETE1Pe4GkHQgxW0nD0rrfEvSmHTf4auBE4ADgdNTXzMza6Nabi/5\ngKTOGsebDtwSEZuAZyT1AIeltp6IeBpA0i2p72N1Z2xmZi3TzDmB8yUtT9NFY1NsArCm1Kc3xarF\nK5I0S1K3pO7+/v4mUjQzs6E0WgTmAPsBU4E+4IqWZQRExNyI6IqIro6OjlYObWZmJcNOB1USEesH\nliVdC3w3PV0LTCp1nZhiDBE3M7M2aehIQNJepacfBwauHFoEzJC0g6TJwBTgJ8DDwBRJkyVtT3Hy\neFHjaZuZWSsMeyQgaQFwNDBOUi9wCXC0pKlAAKuBcwAiYqWkhRQnfDcD50XE62mc84F7gTHAvIhY\n2fK9MTOzutRyddDpFcLXD9H/cuDyCvG7gbvrys7MzEZUQ+cEzEZK54V31b3O6tknjUAmZnnwn40w\nM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLm\nImBmljEXATOzjLkImJllzEXAzCxjwxYBSfMkbZC0ohT7W0mrJC2XdIek3VO8U9KvJC1Lj2tK63xQ\n0qOSeiRdJUkjs0tmZlarWo4E5gPTBsUWAwdHxPuBnwMXldqeioip6XFuKT4H+BzFfYenVBjTzMxG\n2bBFICIeADYOit0XEZvT0yXAxKHGSDem3zUilkREADcCpzaWspmZtUorzgl8Brin9HyypJ9K+pGk\nI1NsAtBb6tObYhVJmiWpW1J3f39/C1I0M7NKmioCkv4c2AzclEJ9wD4RcQjwJeBmSbvWO25EzI2I\nrojo6ujoaCZFMzMbQsM3mpd0FnAycEya4iEiNgGb0vJSSU8B+wNrefOU0cQUMzOzNmroSEDSNODL\nwCkR8Vop3iFpTFp+N8UJ4Kcjog94RdIR6aqgM4E7m87ezMyaMuyRgKQFwNHAOEm9wCUUVwPtACxO\nV3ouSVcCHQV8RdJvgDeAcyNi4KTyn1JcabQjxTmE8nkEMzNrg2GLQEScXiF8fZW+twG3VWnrBg6u\nKzszMxtR/sawmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxlwE\nzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZqKgKS5knaIGlFKbaHpMWS\nnkw/x6a4JF0lqUfSckmHltaZmfo/KWlm63fHzMzqUeuRwHxg2qDYhcD9ETEFuD89BziB4gbzU4BZ\nwBwoigbF/YkPBw4DLhkoHGZm1h41FYGIeADYOCg8HbghLd8AnFqK3xiFJcDukvYCjgcWR8TGiHgR\nWMxbC4uZmY2iZs4JjI+IvrS8DhiflicAa0r9elOsWvwtJM2S1C2pu7+/v4kUzcxsKC05MRwRAUQr\nxkrjzY2Irojo6ujoaNWwZmY2SDNFYH2a5iH93JDia4FJpX4TU6xa3MzM2qSZIrAIGLjCZyZwZyl+\nZrpK6Ajg5TRtdC9wnKSx6YTwcSlmZmZtsm0tnSQtAI4GxknqpbjKZzawUNLZwLPAaan73cCJQA/w\nGvBpgIjYKOky4OHU7ysRMfhks5mZjaKaikBEnF6l6ZgKfQM4r8o484B5NWdnZmYjyt8YNjPLWE1H\nAtYanRfeVVf/1bNPGqFMzMwKPhIwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGP+\nnoBlx9/XMPsdHwmYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLWcBGQdICkZaXHK5K+KOlS\nSWtL8RNL61wkqUfSE5KOb80umJlZoxr+nkBEPAFMBZA0huKm8XdQ3E7yyoj4erm/pAOBGcBBwN7A\n9yXtHxGvN5qDmZk1p1XTQccAT0XEs0P0mQ7cEhGbIuIZinsQH9ai7ZuZWQNaVQRmAAtKz8+XtFzS\nPEljU2wCsKbUpzfF3kLSLEndkrr7+/tblKKZmQ3WdBGQtD1wCvDPKTQH2I9iqqgPuKLeMSNibkR0\nRURXR0dHsymamVkVrTgSOAF4JCLWA0TE+oh4PSLeAK7ld1M+a4FJpfUmppiZmbVJK4rA6ZSmgiTt\nVWr7OLAiLS8CZkjaQdJkYArwkxZs38zMGtTUXxGVtDNwLHBOKfw1SVOBAFYPtEXESkkLgceAzcB5\nvjLIzKy9mioCEfEq8M5BsTOG6H85cHkz2zQzs9bxN4bNzDLmImBmljEXATOzjLkImJllzEXAzCxj\nLgJmZhlzETAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZ\nWcZacaP51ZIelbRMUneK7SFpsaQn08+xKS5JV0nqkbRc0qHNbt/MzBrXqiOBj0XE1IjoSs8vBO6P\niCnA/ek5FDeln5Ies4A5Ldq+mZk1YKSmg6YDN6TlG4BTS/Ebo7AE2H3QjenNzGwUtaIIBHCfpKWS\nZqXY+IjoS8vrgPFpeQKwprRub4q9iaRZkroldff397cgRTMzq6SpG80nH4mItZLeBSyWtKrcGBEh\nKeoZMCLmAnMBurq66lrXzMxq1/SRQESsTT83AHcAhwHrB6Z50s8NqftaYFJp9YkpZmZmbdBUEZC0\ns6RdBpaB44AVwCJgZuo2E7gzLS8CzkxXCR0BvFyaNjIzs1HW7HTQeOAOSQNj3RwR35P0MLBQ0tnA\ns8Bpqf/dwIlAD/Aa8Okmt29mZk1oqghExNPAByrEfwEcUyEewHnNbNPMzFrH3xg2M8uYi4CZWcZc\nBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLWCv+iqiZlXReeFdd/VfPPmmEMjEb\nno8EzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZa7gISJok6QeSHpO0UtIXUvxSSWslLUuP\nE0vrXCSpR9ITko5vxQ6YmVnjmvmewGbggoh4JN1neKmkxantyoj4ermzpAOBGcBBwN7A9yXtHxGv\nN5FDS/n6bjPLTcNHAhHRFxGPpOVfAo8DE4ZYZTpwS0RsiohnKO4zfFij2zczs+a15JyApE7gEOCh\nFDpf0nJJ8ySNTbEJwJrSar0MXTTMzGyENV0EJL0DuA34YkS8AswB9gOmAn3AFQ2MOUtSt6Tu/v7+\nZlM0M7MqmioCkrajKAA3RcTtABGxPiJej4g3gGv53ZTPWmBSafWJKfYWETE3Iroioqujo6OZFM3M\nbAjNXB0k4Hrg8Yj4u1J8r1K3jwMr0vIiYIakHSRNBqYAP2l0+2Zm1rxmrg76MHAG8KikZSl2MXC6\npKlAAKuBcwAiYqWkhcBjFFcWnbclXRlkZpajhotARDwIqELT3UOsczlweaPbNDOz1vI3hs3MMuYi\nYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGmvnGsJm1Qb33vQDf+8Kq85GAmVnG\nXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy9iof1lM0jTgG8AY4LqImD3aOZjZ\n0Or9Qpq/jLb1GtUiIGkMcDVwLNALPCxpUUQ8NhLba+SblWZmORntI4HDgJ6IeBpA0i3AdIqbz5tZ\nJkb6SMN/WqN2iojR25j0P4FpEfHZ9PwM4PCIOH9Qv1nArPT0AOCJUUuyduOAF9qdRIOce3s499G3\nteYNzeW+b0R01NJxi/wDchExF5jb7jyGIqk7IrranUcjnHt7OPfRt7XmDaOX+2hfHbQWmFR6PjHF\nzMysDUa7CDwMTJE0WdL2wAxg0SjnYGZmyahOB0XEZknnA/dSXCI6LyJWjmYOLbRFT1cNw7m3h3Mf\nfVtr3jBKuY/qiWEzM9uy+BvDZmYZcxEwM8uYi0CDJI2R9FNJ3213LvWQtLukWyWtkvS4pA+1O6da\nSPrfklZKWiFpgaTfa3dO1UiaJ2mDpBWl2B6SFkt6Mv0c284cq6mS+9+mfy/LJd0hafd25lhNpdxL\nbRdICknj2pHbcKrlLunz6bVfKelrI7FtF4HGfQF4vN1JNOAbwPci4r3AB9gK9kHSBODPgK6IOJji\nooIZ7c1qSPOBaYNiFwL3R8QU4P70fEs0n7fmvhg4OCLeD/wcuGi0k6rRfN6aO5ImAccBz412QnWY\nz6DcJX2M4i8qfCAiDgK+PhIbdhFogKSJwEnAde3OpR6SdgOOAq4HiIhfR8RL7c2qZtsCO0raFtgJ\neL7N+VQVEQ8AGweFpwM3pOUbgFNHNakaVco9Iu6LiM3p6RKK7/dscaq87gBXAl8GttirYKrk/ifA\n7IjYlPpsGIltuwg05u8p/lG90e5E6jQZ6Af+MU1lXSdp53YnNZyIWEvxKeg5oA94OSLua29WdRsf\nEX1peR0wvp3JNOEzwD3tTqJWkqYDayPiZ+3OpQH7A0dKekjSjyT9/khsxEWgTpJOBjZExNJ259KA\nbYFDgTkRcQjwKlvutMRvpfnz6RRFbG9gZ0n/q71ZNS6K67K32E+l1Uj6c2AzcFO7c6mFpJ2Ai4G/\nbHcuDdoW2AM4Avg/wEJJavVGXATq92HgFEmrgVuA/ybp2+1NqWa9QG9EPJSe30pRFLZ0fwg8ExH9\nEfEb4HbgD9qcU73WS9oLIP0ckUP7kSLpLOBk4FOx9Xy5aD+KDw4/S/9fJwKPSNqzrVnVrhe4PQo/\noZh5aPmJbReBOkXERRExMSI6KU5O/ltEbBWfSiNiHbBG0gEpdAxbx5/xfg44QtJO6ZPQMWwFJ7QH\nWQTMTMszgTvbmEtd0o2gvgycEhGvtTufWkXEoxHxrojoTP9fe4FD0/+DrcG/AB8DkLQ/sD0j8BdR\nXQTy83ngJknLganAX7c5n2GlI5dbgUeARyn+3W6xfw5A0gLgx8ABknolnQ3MBo6V9CTFkc0WeUe9\nKrl/E9gFWCxpmaRr2ppkFVVy3ypUyX0e8O502egtwMyROArzn40wM8uYjwTMzDLmImBmljEXATOz\njLkImJllzEXAzCxjLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAIWsrpub696",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "colab_type": "code",
        "outputId": "f7eea551-c654-443b-b2ba-8122ba02db0a",
        "id": "oPsbo8mBMj51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#all unique characters go here, padding included!\n",
        "tokens = np.append(np.unique(list(\"\".join(names))), pad_token)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YJqziQXb69-",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "pjptB7Ymb69_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = dict(zip(tokens, range(len(tokens))))###create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "WMSSl7xib6-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "OPb3tAlrb6-E",
        "colab_type": "code",
        "outputId": "4b96c987-67a4-479c-d494-5ffb93eb1e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0  3 30 29 35 29 33 40 55]\n",
            " [ 0  9 40 43 46 53 55 55 55]\n",
            " [ 0 18 46 37 47 47 37 33 55]\n",
            " [ 0  9 37 43 50 29 42 42 33]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAnmY2gzb6-H",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "A0zRv83Db6-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "vXB15Wo1b6-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(input_shape=(embedding_size+rnn_num_units,), units=rnn_num_units, activation=\"tanh\")\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(input_shape=(rnn_num_units,), units=n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZZ-uOsBb6-Q",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "Fj2mTXXXb6-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1) \n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_t_emb)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEkh6RSDb6-T",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "1FqAetfIb6-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPraZ2APb6-W",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "OJh01VUqb6-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlBZkq_Wb6-Z",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "7ECcXZxhb6-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wXz1dwb6-e",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "uWemB5QKb6-f",
        "colab_type": "code",
        "outputId": "3b2013dd-e20e-4397-fd26-902ddb7d3350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk7tSStmQJnellLIhTe5KKWVD/x/SXWorENVVuAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5kOOnjDb6-k",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "yb39Nx8gb6-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "Ud53rkidb6-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "lMHr6Ic6b6-s",
        "colab_type": "code",
        "outputId": "3edc92af-3a45-4212-ac6e-787a05249294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Yafvenneyla\n",
            " Re\n",
            " Ubettas\n",
            " Yen\n",
            " Ch\n",
            " Mia\n",
            " Cole\n",
            " Baceely\n",
            " Ma\n",
            " Jer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "A_cZCaDLb6-z",
        "colab_type": "code",
        "outputId": "66f6cd12-601b-4500-effb-d5ea613572a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trumphisitah\n",
            " Trumpaptailide\n",
            " Trumpy\n",
            " Trumph\n",
            " Trumph\n",
            " Trumpinolma\n",
            " Trumpionan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTVVbNAdb6-4",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "ulBWmIkAb6-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"wtMCNwzX7XfGraFE\"\n",
        "COURSERA_EMAIL = \"redsun1988@rambler.ru\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "k6eehJchb6_E",
        "colab_type": "code",
        "outputId": "9c568cf4-dea9-443f-c27a-1068ab866357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKDZqRt-b6_I",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "60edom-pb6_J",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "TKKw6t5Bb6_K",
        "colab_type": "code",
        "outputId": "b332352a-9c2d-4446-b242-5ba1cd0feef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 20:41:53.046747 140350722643840 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0805 20:41:53.057876 140350722643840 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENTHrRmkb6_Q",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "chot7ztjb6_R",
        "colab_type": "code",
        "outputId": "b8757759-f69e-45f5-f5ef-0a6136af9b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "H0myqCT1b6_V",
        "colab_type": "code",
        "outputId": "6929482c-accd-4dda-f8e4-e6c59522325e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 20:42:57.126080 140350722643840 deprecation.py:323] From <ipython-input-44-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-62766a2145fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_num_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# framework.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;31m# Handle Keras mask propagation from previous layer to current layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[1;32m    246\u001b[0m           layer_inputs, processed_ops, created_layers)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1158\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       raise ValueError(\n\u001b[0;32m--> 500\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Operation 'rnn_2/while/IsVariableInitialized' has been marked as not fetchable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB05G2mhhU_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}